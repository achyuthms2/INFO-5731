{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwlpO53ybU9p"
      },
      "source": [
        "## The third In-class-exercise (02/08/2022, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etuLvzRQbU9r"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvquqGTVbU9r"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QiRtsG3bU9r"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "The smart phone market in India is very huge and Redmi is one of the most popular budget range smart phones in the Indian market. \n",
        "This smartphone and its reviews is the best choice for me to collect the required 1000 samples of data.\n",
        "Question - Is the Redmi note 4 smartphone a good and suggestabke smart phone in the lower budget segment? Collect the consumer review data from the reviews\n",
        "page and submit those reviews which contains the customer opinions, its pros and cons which could be helpful to make a purchase decision.\n",
        "\n",
        "This is acheived by web scrapping with the help of beautiful soap library. This library is used to scrap the required data from the web pages.\n",
        "The class and tags of the required data are collected from the web pages and are included in the code to extract that information.\n",
        "The extracted data is appended into a list to view it in a table form. In this I have extracted 1010 reviews of the Redmi note 4.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naITvStJbU9s"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "hRVbx8x1bU9s",
        "outputId": "fe852ffe-a09a-40b6-948c-65bd4d3bafe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data frame is 1010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-19b189bd-904a-400c-9f05-0338ed8803b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Glimpse of Review</th>\n",
              "      <th>Full Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Great product</td>\n",
              "      <td>For Basic users :\\n1. Good battery life\\n2. Ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>Very nice mobile very fast finger unlock aweso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Worth every penny</td>\n",
              "      <td>◆◆Redmi Note 4 review◆◆\\n\\n1.Excellent  perfor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wonderful</td>\n",
              "      <td>I was always a Moto lover but my trust got bui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Worth the money</td>\n",
              "      <td>Delivered before 1 day of expected delivery.ni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>Brilliant</td>\n",
              "      <td>First of all thank you to flipkart for extra d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1006</th>\n",
              "      <td>Must buy!</td>\n",
              "      <td>Just go for it. This phone is lit in terms of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>Fabulous!</td>\n",
              "      <td>It's a awesome mobile with a really good batte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>Good quality product</td>\n",
              "      <td>Nice phone, front cam quality need to improve ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>Nice product</td>\n",
              "      <td>Before you ordered this smartphone please read...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1010 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19b189bd-904a-400c-9f05-0338ed8803b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19b189bd-904a-400c-9f05-0338ed8803b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19b189bd-904a-400c-9f05-0338ed8803b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Glimpse of Review                                        Full Review\n",
              "0            Great product  For Basic users :\\n1. Good battery life\\n2. Ca...\n",
              "1                Wonderful  Very nice mobile very fast finger unlock aweso...\n",
              "2        Worth every penny  ◆◆Redmi Note 4 review◆◆\\n\\n1.Excellent  perfor...\n",
              "3                Wonderful  I was always a Moto lover but my trust got bui...\n",
              "4          Worth the money  Delivered before 1 day of expected delivery.ni...\n",
              "...                    ...                                                ...\n",
              "1005             Brilliant  First of all thank you to flipkart for extra d...\n",
              "1006             Must buy!  Just go for it. This phone is lit in terms of ...\n",
              "1007             Fabulous!  It's a awesome mobile with a really good batte...\n",
              "1008  Good quality product  Nice phone, front cam quality need to improve ...\n",
              "1009          Nice product  Before you ordered this smartphone please read...\n",
              "\n",
              "[1010 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup, NavigableString\n",
        "import pandas as pd\n",
        "\n",
        "headings = []  # List to store headings\n",
        "review = []  # List to store reviews\n",
        "number = 1\n",
        "while True:\n",
        "    link = \"https://www.flipkart.com/redmi-note-4-black-64-gb/product-reviews/itmeqe48766xqzb7?pid=MOBEQ98TABTWXGTD&lid=LSTMOBEQ98TABTWXGTD79S5H4&marketplace=FLIPKART&page=\" + str(\n",
        "        number)  # Appending page variable\n",
        "    page = requests.get(link)  # Rendering html response of the link\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\n",
        "    review_headings = soup.find_all(class_='_2-N8zT')  # Finding all the review headings by using class\n",
        "    reviews = soup.find_all(class_='t-ZTKy')  # Finding all the review divs\n",
        "    for ele, sub_ele in zip(review_headings, reviews):  \n",
        "        headings.append(ele.text)  # Inserting data\n",
        "        contents = sub_ele.contents[0].contents[0].contents\n",
        "        result = ''\n",
        "        for content in contents: # Iterating through contents to generate full review\n",
        "            result = result + (content if isinstance(content, NavigableString) else \"\\n\")  # br tag being replaced with \\n\n",
        "        review.append(result)\n",
        "    if len(headings) > 1000:  # Checking for limit 1000\n",
        "        break\n",
        "    else:\n",
        "        number += 1\n",
        "\n",
        "df = pd.DataFrame(list(zip(headings, review)), columns=['Glimpse of Review', 'Full Review'])  # Creating Dataframe\n",
        "print(\"Length of data frame is {0}\".format(len(df)))\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6Tt5lNIbU9t"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2871imoEbU9t"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "HEADERS = ({'User-Agent':\n",
        "           'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36',\n",
        "                           'Accept-Language': 'en-US, en;q=0.5'})\n",
        "\n",
        "\n",
        "def getsoup(link): # takes a url and returns a beautifulsoap object\n",
        "    webpage = requests.get(link, headers= HEADERS)\n",
        "    soup = bs(webpage.content, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "def getTitle(soup): # getting title from the articles\n",
        "    return soup.find('h3', {'class': 'gs_rt'}).text\n",
        "\n",
        "\n",
        "def getPublicationInfo(soup): # getting publication information from the articles\n",
        "    return soup.find('div', {'class': 'gs_a'}).text\n",
        "\n",
        "\n",
        "def getPublisher(soup):\n",
        "    return soup.select('a')[0].get_text()\n",
        "\n",
        "\n",
        "def getAuthor(soup):\n",
        "    return soup.find_all('div', {'class': 'gs_a'})[0].get_text().split('-')[0]\n",
        "\n",
        "\n",
        "def getYear(soup):\n",
        "    a = soup.find_all('div', {'class': 'gs_a'})[0].get_text()\n",
        "    temp = re.findall(r'\\d+', a)\n",
        "    res = list(map(int, temp))\n",
        "    return str(res)[1:-1]\n",
        "\n",
        "\n",
        "def getAbstract(soup):\n",
        "    return soup.find_all('div', {'class': 'gs_rs'})[0].get_text()\n",
        "\n",
        "\n",
        "def extractData(soup): # extracting list of articles from the given soup\n",
        "    articles = []\n",
        "    print(soup)\n",
        "    for item in soup.select('[data-lid]'):\n",
        "        data = dict()\n",
        "        data[\"Title\"] = getTitle(item)\n",
        "        data[\"Publication Information\"] = getPublicationInfo(item)\n",
        "        data[\"Publisher\"] = getPublisher(item)\n",
        "        data[\"Author\"] = getAuthor(item)\n",
        "        data[\"year\"] = getYear(item)\n",
        "        data[\"Abstract\"] = getAbstract(item)\n",
        "        articles.append(data)\n",
        "    return articles\n",
        "\n",
        "\n",
        "def extractArticles(): # calling the paginated url and extracting articles from the soup\n",
        "    articles = []\n",
        "    for number in range(0, 100):\n",
        "        link = 'https://scholar.google.com/scholar?start={}0&q=web+scrapping&hl=en&as_sdt=0,44'.format(number)\n",
        "        soup = getsoup(link)\n",
        "        articles.extend(extractData(soup))\n",
        "    return articles\n",
        "\n",
        "\n",
        "articles = extractArticles()\n",
        "df = pd.DataFrame(articles)\n",
        "print(\"Length of data frame is {0}\".format(len(df)))\n",
        "df.to_csv('articles.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaScLNkHbU9t"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epavlZaCbU9u"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "import tweepy as tw\n",
        "import pandas as pd\n",
        "\n",
        "api_key = \"mmddCbhgMWXyYEmQ4V2SpCLxt\"\n",
        "api_secret = \"XKGeBBCh3nZoVpCncb1GAMPPn8TUVkfaEpfuu6gWajB2UQPAJ9\"\n",
        "access_token = \"3222012250-Uj8I4CuODu3w54UrHOyrXlSPyHGy2RYEDFFJZUF\"\n",
        "access_token_secret = \"LXxFcdCjhTmxzehosxbN3fXvh7bSAVRUvlJFRaHXilWxu\"\n",
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAALFfZAEAAAAA6D8myzH84FUC0E1DJ8s1qdXwfgE%3DAulQ7owkDXyEpT4qyGfB6pJ8vwG36NXqPrnSRxVS49stWfHVON\"\n",
        "auth = tw.OAuthHandler(api_key, api_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "twitter = tw.API(auth, wait_on_rate_limit=True)\n",
        "search_query = \"#naruto #attackontitan\"\n",
        "\n",
        "\n",
        "def getRawTweets():\n",
        "    tweets = tw.Cursor(twitter.search_tweets,\n",
        "                       q=search_query,\n",
        "                       lang=\"en\",\n",
        "                       since=\"2021-09-16\").items(50)\n",
        "    # tweets = twitter.search_all_tweets(query=search_query, max_results=50)\n",
        "     return [tweet for tweet in tweets]\n",
        "\n",
        "\n",
        "def getTweets():\n",
        "    rawTweets = getRawTweets()\n",
        "    tweets = []\n",
        "\n",
        "    for rawTweet in rawTweets:\n",
        "        hashtags = []\n",
        "        text = ''\n",
        "        try:\n",
        "            for hashtag in rawTweet.entities[\"hashtags\"]:\n",
        "                hashtags.append(hashtag[\"text\"])\n",
        "            text = twitter.get_status(id=rawTweet.id, tweet_mode='extended').full_text\n",
        "        except:\n",
        "            pass\n",
        "        data = {'user_name': rawTweet.user.name,\n",
        "                'user_location': rawTweet.user.location,\n",
        "                'user_description': rawTweet.user.description,\n",
        "                'user_verified': rawTweet.user.verified,\n",
        "                'date': rawTweet.created_at,\n",
        "                'text': text,\n",
        "                'hashtags': [hashtags if hashtags else None],\n",
        "                'source': rawTweet.source}\n",
        "        tweets.append(data)\n",
        "    return tweets\n",
        "\n",
        "\n",
        "tweets = getTweets()\n",
        "df = pd.DataFrame(tweets)\n",
        "df.to_csv('tweets.csv')\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In-class-exercise-02-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}